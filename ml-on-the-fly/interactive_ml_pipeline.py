import os
import json
import pandas as pd
from pprint import pprint

# Assuming ml_service.py, csv_handler.py, model_generator.py are in the same directory or accessible in PYTHONPATH
from ml_service import MLService

def display_dict(data: dict, indent=1):
    for key, value in data.items():
        print('\t' * indent + str(key) + ':', end='')
        if isinstance(value, dict):
            print()
            display_dict(value, indent + 1)
        else:
            print('\t' * (indent + 1) + str(value))

def run_interactive_pipeline():
    print("===== ML-on-the-Fly: Interactive Pipeline =====")
    ml_service = MLService()

    # 1. Get CSV file path from user
    while True:
        csv_path = input("\nEnter the full path to your CSV file: ").strip()
        if not os.path.exists(csv_path):
            print(f"Error: File not found at '{csv_path}'. Please try again.")
            continue
        if not csv_path.lower().endswith('.csv'):
            print(f"Error: File does not appear to be a CSV file (expected .csv extension).")
            continue
        
        try:
            with open(csv_path, 'rb') as f:
                file_content = f.read()
            print(f"Successfully read file: {csv_path}")
            break
        except Exception as e:
            print(f"Error reading file: {e}. Please try again.")

    # 2. Process CSV
    print("\nProcessing CSV file...")
    result = ml_service.process_csv(file_content)
    if not result.get("success"):
        print(f"Error processing CSV: {result.get('error', 'Unknown error')}")
        if result.get('traceback'):
            print("Traceback:")
            print(result['traceback'])
        return
    
    print("CSV processed successfully!")
    data_summary = result["data_summary"]
    print("\nData Summary:")
    print(f"- Rows: {data_summary['num_rows']}")
    print(f"- Columns: {data_summary['num_cols']}")
    print("\nAvailable columns:")
    for i, col_name in enumerate(data_summary['columns']):
        print(f"  {i+1}. {col_name} (dtype: {data_summary['dtypes'].get(col_name, 'N/A')})")
    
    # 3. Select target column
    while True:
        try:
            target_col_index_str = input("\nEnter the number of the column you want to predict (target variable): ")
            target_col_index = int(target_col_index_str) - 1
            if 0 <= target_col_index < len(data_summary['columns']):
                target_column = data_summary['columns'][target_col_index]
                print(f"You selected '{target_column}' as the target column.")
                break
            else:
                print("Invalid column number. Please choose from the list.")
        except ValueError:
            print("Invalid input. Please enter a number.")

    result = ml_service.select_target_column(target_column)
    if not result.get("success"):
        print(f"Error selecting target column: {result.get('error', 'Unknown error')}")
        return
    problem_type = result['problem_type']
    print(f"Target column '{target_column}' selected. Detected problem type: {problem_type}")

    # 4. Generate Model
    print("\nGenerating model...")
    # This might take some time
    gen_result = ml_service.generate_model() # problem_type is already set in ml_service
    if not gen_result.get("success"):
        print(f"Error generating model: {gen_result.get('error', 'Unknown error')}")
        if gen_result.get('traceback'):
            print("Traceback:")
            print(gen_result['traceback'])
        return
    print(gen_result.get("message", "Model generated."))
    if gen_result.get("model_source"):
        print(f"Model code was generated by: {gen_result['model_source']}")

    # 5. Train Model
    print("\nTraining model...")
    # This also might take some time
    train_result = ml_service.train_model()
    if not train_result.get("success"):
        print(f"Error training model: {train_result.get('error', 'Unknown error')}")
        if train_result.get('traceback'):
            print("Traceback:")
            print(train_result['traceback'])
        return
    
    print(train_result.get("message", "Model trained."))
    print("\nTraining Summary:")
    pprint(train_result.get("training_summary", {}))

    # 6. Get Insights (Optional)
    if input("\nDo you want to see model insights? (yes/no): ").strip().lower() == 'yes':
        print("\nFetching insights...")
        insights_result = ml_service.get_insights()
        if insights_result.get("success"):
            print("\nModel Insights:")
            pprint(insights_result.get("insights", {}))
        else:
            print(f"Error getting insights: {insights_result.get('error', 'Unknown error')}")

    # 7. Make a prediction (Optional)
    if input("\nDo you want to make a sample prediction? (yes/no): ").strip().lower() == 'yes':
        print("\nPlease provide input data for prediction.")
        print("The features are (excluding target '{target_column}'):")
        
        feature_names = [col for col in data_summary['columns'] if col != target_column]
        sample_input_data = {}
        
        for feature in feature_names:
            dtype = data_summary['dtypes'].get(feature, 'object')
            while True:
                val_str = input(f"  Enter value for '{feature}' (type: {dtype}): ")
                try:
                    if 'int' in dtype.lower():
                        sample_input_data[feature] = int(val_str)
                    elif 'float' in dtype.lower():
                        sample_input_data[feature] = float(val_str)
                    elif 'bool' in dtype.lower():
                        sample_input_data[feature] = val_str.lower() in ['true', '1', 't', 'y', 'yes']
                    else: # Treat as string (object)
                        sample_input_data[feature] = val_str
                    break
                except ValueError:
                    print(f"Invalid input type for {feature}. Expected {dtype}. Please try again.")
        
        print("\nMaking prediction with your sample data...")
        predict_result = ml_service.predict(sample_input_data)
        if predict_result.get("success"):
            print("\nPrediction Result:")
            print(f"  Predicted value for '{target_column}': {predict_result['prediction']}")
        else:
            print(f"Error making prediction: {predict_result.get('error', 'Unknown error')}")
            if predict_result.get('traceback'):
                print("Traceback:")
                print(predict_result['traceback'])
                
    # 8. Show Model Code (Optional)
    if input("\nDo you want to see the generated model code? (yes/no): ").strip().lower() == 'yes':
        code_result = ml_service.get_model_code()
        if code_result.get("success"):
            print(f"\nModel was generated by: {code_result.get('model_source', 'N/A')}")
            print("--- Generated Model Code ---")
            print(code_result.get("model_code"))
            print("--------------------------")
        else:
            print(f"Error retrieving model code: {code_result.get('error', 'Unknown error')}")

    print("\n===== Interactive Pipeline Finished =====")

if __name__ == "__main__":
    run_interactive_pipeline() 